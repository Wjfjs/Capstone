

<h1>yolo 환경 구축 조사</h1>
<a href="https://webnautes.tistory.com/m/1850">CUDA 사용하기 위한 PyTorch 설치</a><br>
<a href="https://youtu.be/ert1zNdIpEA?si=kbUGK8Bd_WCisvc9">Miniconda를 사용한 Python환경 구축</a><br>
<a href="https://webnautes.tistory.com/m/1851">YOLO v8 환경 구축</a><br><br>

#실행순서<br>
비쥬얼코드 와 파이썬3.11 설치<br><br>

anaconda설치<br>
anaconda prompt에서<br><br>

conda create -n newenv python=3.11<br>
conda env list<br>
conda activate newenv<br><br>

비쥬얼코드에서<br>
python설치 확인하고 ctr+shift+p로 default프로필 command 선택<br>
view -> terminal로 명령창 꺼내기<br>
C:\Users\315\miniconda3\Scripts\activate<br><br>

PyTorch를 위한 가상환경을 생성<br>
conda create -n pytorch python==3.10<br><br>

ctr+shift+p후 select interpreter후 pytorch선택<br><br>

가상화 활성화<br>
conda activate pytorch<br><br>

PyTorch를 설치<br>
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118<br>
python -c "import torch; print(torch.cuda.is_available())"<br>
true 확인<br><br>

필요한 패키지를 설치합니다.<br>
pip install opencv-python<br>
pip install ultralytics<br><br>

코드 복붙한 뒤 우클릭으로  Run Python 실행 1번째 줄로<br><br>

#코드<br>

    import cv2
    from ultralytics import YOLO
    
    # Load the YOLOv8 model
    model = YOLO('yolov8n.pt')
    
    # 동영상 파일 사용시
    video_path = ".mp4"
    cap = cv2.VideoCapture(video_path)
    
    # webcam 사용시
    # cap = cv2.VideoCapture(0)
    
    # Loop through the video frames
    while cap.isOpened():
        # Read a frame from the video
        success, frame = cap.read()
    
        if success:
            # Run YOLOv8 inference on the frame
            results = model(frame)
    
            # Visualize the results on the frame
            annotated_frame = results[0].plot()
    
            # Display the annotated frame
            cv2.imshow("YOLOv8 Inference", annotated_frame)
    
            # Break the loop if 'q' is pressed
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        else:
            # Break the loop if the end of the video is reached
            break
    
    # Release the video capture object and close the display window
    cap.release()
    cv2.destroyAllWindows()

<h1>교통량 조사</h1>
<a href="https://www.gjtic.go.kr/">광주</a><br>
<a href="https://www.data.go.kr/data/15098622/openapi.do#tab_layer_detail_function">광주 데이터 조회</a><br>
<a href="https://topis.seoul.go.kr/refRoom/openRefRoom_2.do">서울</a><br><br>

<h1>기타 자료조사</h1>
<a href="https://blog.testworks.co.kr/deep-learning-for-traffic-counting/">https://blog.testworks.co.kr/deep-learning-for-traffic-counting/</a><br>
<a href="https://velog.io/@parksh089g/yolov5-custom-train-2">https://velog.io/@parksh089g/yolov5-custom-train-2</a><br>
<a href="https://sdk17586.tistory.com/71">https://sdk17586.tistory.com/71</a><br>
<a href="https://swiftcam.tistory.com/344">https://swiftcam.tistory.com/344</a><br>
<a href="https://prlabhotelshoe.tistory.com/15"></a>https://prlabhotelshoe.tistory.com/15<br>
<a href="https://saurus2.tistory.com/entry/Yolo-v3-Object-Detection-%EB%AC%BC%EC%B2%B4-%EC%9D%B8%EC%8B%9D-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-darknet-%EC%86%8C%EC%8A%A4-%EB%B6%84%EC%84%9D">https://saurus2.tistory.com/entry/Yolo-v3-Object-Detection-%EB%AC%BC%EC%B2%B4-%EC%9D%B8%EC%8B%9D-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-darknet-%EC%86%8C%EC%8A%A4-%EB%B6%84%EC%84%9D</a><br>
<a href="https://blog.testworks.co.kr/deep-learning-for-traffic-counting/">https://blog.testworks.co.kr/deep-learning-for-traffic-counting/</a><br>
<a href="https://sdk17586.tistory.com/m/71">https://sdk17586.tistory.com/m/71</a><br>
<a href="https://m.blog.naver.com/PostView.naver?blogId=tory0405&logNo=223155108671&categoryNo=12&proxyReferer=">https://m.blog.naver.com/PostView.naver?blogId=tory0405&logNo=223155108671&categoryNo=12&proxyReferer=</a><br>
<a href="https://panggu15.github.io/detection/%EA%B0%84%EB%8B%A8%ED%95%9C-YOLO-%EA%B5%AC%ED%98%84(OpenCV)/">https://panggu15.github.io/detection/%EA%B0%84%EB%8B%A8%ED%95%9C-YOLO-%EA%B5%AC%ED%98%84(OpenCV)/</a><br><br>
